{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff90db7",
   "metadata": {},
   "source": [
    "Let's do some basic data cleaning! First let's drop some duplicate tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv('SpotifyFeatures.csv')\n",
    "spotify_df[spotify_df['track_id'] == \"6iOvnACn4ChlAw4lWUU4dd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99668aa",
   "metadata": {},
   "source": [
    "For this id, we can see that if a song appears across generes, it will be a duplicate entry. For simplicity, I'm going to remove duplicate IDs and keep the first ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = spotify_df.drop_duplicates(subset=[\"track_id\"], keep=\"first\")\n",
    "spotify_df[spotify_df['track_id'] == \"6iOvnACn4ChlAw4lWUU4dd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(spotify_df, x=\"popularity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41633eaf",
   "metadata": {},
   "source": [
    "In this histogram, we can see that the dataset contains a lot of (no judgement!) low-popularity songs. Let's add a baseline popularity to analyze more relevant songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84873798",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(spotify_df[spotify_df['popularity'] > 10], x=\"popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91792f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = spotify_df[spotify_df[\"popularity\"] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a439c1f",
   "metadata": {},
   "source": [
    "I want to store track metadata for retrieval in the future, and eventually the results of our cluster analysis. Let's store the data in our DuckDB instance and stand up some initial tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_db import DB_NAME\n",
    "import duckdb\n",
    "\n",
    "with duckdb.connect(database=DB_NAME) as con:\n",
    "    con.execute(\"CREATE TABLE track AS SELECT * FROM spotify_df\")\n",
    "    con.execute(\"ALTER TABLE track ADD PRIMARY KEY (track_id)\")\n",
    "    con.execute(\"CREATE TABLE cluster (id INTEGER PRIMARY KEY, x FLOAT, y FLOAT, size FLOAT)\")\n",
    "    con.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE track_to_cluster \n",
    "        (track_id VARCHAR, cluster_id INTEGER, \n",
    "        FOREIGN KEY (track_id) REFERENCES track (track_id),\n",
    "        FOREIGN KEY (cluster_id) REFERENCES cluster (id))\n",
    "        \"\"\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61046f2a",
   "metadata": {},
   "source": [
    "Great! Now we can start some analysis to store in our db. We have a few categorical variables, like genre and key with many options, and mode that we could consider to be a boolean. Because of this mix of data types, I will first calculate a gower distance matrix to find similary between tracks. We'll at this point also define our train & test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18aa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# use our track id as index for convenience & drop metadata\n",
    "spotify_df = shuffle(spotify_df)\n",
    "df = spotify_df.set_index('track_id').drop(columns=['artist_name','track_name']).head(10000)\n",
    "\n",
    "dist_matrix = gower.gower_matrix(df)\n",
    "\n",
    "indices = np.arange(len(df))\n",
    "train_idx, test_idx = train_test_split(indices,train_size=0.8,random_state=42)\n",
    "dist_matrix_train = dist_matrix[np.ix_(train_idx, train_idx)]\n",
    "dist_matrix_test = dist_matrix[np.ix_(test_idx, test_idx)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da3e4c",
   "metadata": {},
   "source": [
    "With our distance matrix computed, we can do a basic parameter sweep with sklearn's Agglomerative Clustering function. I chose this as it accepts non-euclidean distances as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "cluster_scores = {}\n",
    "for n in range(2, 15):\n",
    "    cluster = AgglomerativeClustering(metric=\"precomputed\", n_clusters=n, linkage=\"average\")\n",
    "    cluster.fit(dist_matrix_train)\n",
    "    pred_labels = cluster.fit_predict(dist_matrix_test)\n",
    "\n",
    "    score = silhouette_score(dist_matrix_test, pred_labels, metric=\"precomputed\")\n",
    "    cluster_scores[n] = score\n",
    "\n",
    "best_cluster = max(cluster_scores, key=cluster_scores.get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=best_cluster, metric=\"precomputed\", linkage=\"average\")\n",
    "cluster.fit(dist_matrix_train)\n",
    "cluster.fit_predict(dist_matrix)\n",
    "\n",
    "df[\"cluster_label\"] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "t_sne = TSNE(n_components=2, metric='precomputed', init='random', random_state=42)\n",
    "xy = t_sne.fit_transform(dist_matrix)\n",
    "sns.scatterplot(x=xy[:, 0], y=xy[:, 1], hue=df['cluster_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88126749",
   "metadata": {},
   "source": [
    "Our gower distance calc resulted in some overlapping clusters - let's try a different method to find similar song clusters! This time I'll use k-means clustering and encode the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df: pd.DataFrame = spotify_df.set_index('track_id').drop(columns=['artist_name','track_name']).head(10000)\n",
    "categorical_df = df.select_dtypes(exclude=['number']).columns\n",
    "def encode(column: pd.Series):\n",
    "    unique_vals = column.unique()\n",
    "    encoding_map = {col: i for i,col in enumerate(unique_vals)}\n",
    "    column = column.map(encoding_map)\n",
    "    return column\n",
    "\n",
    "df = df.apply(lambda x: encode(x) if x.name in categorical_df else x)\n",
    "scaler = StandardScaler()\n",
    "df_znorm = scaler.fit_transform(df)\n",
    "best_cluster = {}\n",
    "\n",
    "for n in range(2,20):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "    cluster = kmeans.fit(df_znorm)\n",
    "    best_cluster[n] = cluster.inertia_\n",
    "\n",
    "sns.pointplot(x=best_cluster.keys(), y=best_cluster.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cluster_n = 12\n",
    "kmeans = KMeans(n_clusters=best_cluster_n, random_state=42)\n",
    "kmeans.fit_predict(df_znorm)\n",
    "centroids = kmeans.cluster_centers_\n",
    "df[\"cluster_labels\"] = kmeans.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "t_sne = TSNE(n_components=2, random_state=42)\n",
    "xy_centroids = t_sne.fit_transform(np.vstack([df_znorm, centroids]))\n",
    "\n",
    "xy = xy_centroids[:-len(centroids)]\n",
    "centroid_coords = xy_centroids[-len(centroids):]\n",
    "\n",
    "sns.scatterplot(x=xy[:,0], y=xy[:,1], hue=df['cluster_labels'], palette='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster_grid import generate_cluster_positions_df\n",
    "\n",
    "cluster_info = generate_cluster_positions_df(df['cluster_labels'], n_clusters=best_cluster_n, layout_type='circular')\n",
    "cluster_info = cluster_info.rename(columns={'cluster_id':'id', 'x_position':'x', 'y_position':'y','cluster_size':'size'})\n",
    "with duckdb.connect(database=DB_NAME) as con:\n",
    "    con.execute(\"INSERT INTO cluster BY NAME SELECT * FROM cluster_info\")\n",
    "\n",
    "cluster_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12458f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "trackdf = df[['cluster_labels']].reset_index().rename(columns={'cluster_labels':'cluster_id'})\n",
    "with duckdb.connect(database=DB_NAME) as con:\n",
    "    con.execute(\"INSERT INTO track_to_cluster BY NAME SELECT * FROM trackdf\")\n",
    "\n",
    "trackdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_znorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
